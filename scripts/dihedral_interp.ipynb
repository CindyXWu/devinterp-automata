{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IMIMIXuoqUT",
        "outputId": "35a34548-287d-4836-da8b-cf5c6515dad3"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab # type: ignore\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "import os, sys\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Code to download the necessary files (e.g. solutions, test funcs)\n",
        "    if not os.path.exists(\"chapter1_transformers\"):\n",
        "        !curl -o /content/main.zip https://codeload.github.com/callummcdougall/ARENA_2.0/zip/refs/heads/main\n",
        "        !unzip /content/main.zip 'ARENA_2.0-main/chapter1_transformers/exercises/*'\n",
        "        sys.path.append(\"/content/ARENA_2.0-main/chapter1_transformers/exercises\")\n",
        "        os.remove(\"/content/main.zip\")\n",
        "        os.rename(\"ARENA_2.0-main/chapter1_transformers\", \"chapter1_transformers\")\n",
        "        os.rmdir(\"ARENA_2.0-main\")\n",
        "        os.chdir(\"chapter1_transformers/exercises\")\n",
        "else:\n",
        "    from IPython import get_ipython\n",
        "    ipython = get_ipython()\n",
        "    ipython.run_line_magic(\"load_ext\", \"autoreload\")\n",
        "    ipython.run_line_magic(\"autoreload\", \"2\")\n",
        "\n",
        "    CHAPTER = r\"chapter1_transformers\"\n",
        "    CHAPTER_DIR = r\"./\" if CHAPTER in os.listdir() else os.getcwd().split(CHAPTER)[0]\n",
        "    EXERCISES_DIR = CHAPTER_DIR + f\"{CHAPTER}/exercises\"\n",
        "    sys.path.append(EXERCISES_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16d0pi3rNVjH",
        "outputId": "6f897874-d5db-479b-e9de-8fd9a12dc78d"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    # Install packages\n",
        "    %pip install einops\n",
        "    %pip install jaxtyping\n",
        "    %pip install transformer_lens\n",
        "    %pip install git+https://github.com/callummcdougall/CircuitsVis.git#subdirectory=python\n",
        "    %pip install s3fs\n",
        "    %pip install omegaconf\n",
        "    %pip install git+https://github.com/CindyXWu/devinterp-automata.git\n",
        "    %pip install torch-ema\n",
        "    \n",
        "    !curl -o /content/main.zip https://codeload.github.com/CindyXWu/devinterp-automata/zip/refs/heads/main\n",
        "    !unzip -o /content/main.zip -d /content/\n",
        "    sys.path.append(\"/content/devinterp-automata/\")\n",
        "    os.remove(\"/content/main.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87aqhevcowv4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import plotly.express as px\n",
        "from typing import List, Union, Optional, Dict, Tuple\n",
        "from jaxtyping import Int, Float\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import einops\n",
        "import re\n",
        "import functools\n",
        "from tqdm import tqdm\n",
        "from IPython.display import display\n",
        "import webbrowser\n",
        "import gdown\n",
        "from transformer_lens.hook_points import HookPoint\n",
        "from transformer_lens import utils, HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
        "from transformer_lens.utils import to_numpy\n",
        "\n",
        "import circuitsvis as cv\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "torch.set_grad_enabled(False)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "MAIN = __name__ == \"__main__\"\n",
        "\n",
        "import wandb\n",
        "from pathlib import Path\n",
        "import os\n",
        "import yaml\n",
        "import s3fs\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "from di_automata.config_setup import *\n",
        "from di_automata.constructors import (\n",
        "    construct_model,\n",
        "    create_dataloader_hf,\n",
        ")\n",
        "from di_automata.tasks.data_utils import take_n\n",
        "import plotly.io as pio\n",
        "\n",
        "# AWS\n",
        "s3 = s3fs.S3FileSystem()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1e9En6gz_al"
      },
      "outputs": [],
      "source": [
        "chapter = r\"chapter1_transformers\"\n",
        "exercises_dir = Path(f\"{os.getcwd().split(chapter)[0]}/{chapter}/exercises\").resolve()\n",
        "if str(exercises_dir) not in sys.path: sys.path.append(str(exercises_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUMf5cdb3d8w"
      },
      "outputs": [],
      "source": [
        "def imshow_attention(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"Viridis\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
        "\n",
        "def line(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    px.line(utils.to_numpy(tensor), labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
        "\n",
        "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
        "    x = utils.to_numpy(x)\n",
        "    y = utils.to_numpy(y)\n",
        "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lP9I1Pbh0lIM"
      },
      "outputs": [],
      "source": [
        "update_layout_set = {\"xaxis_range\", \"yaxis_range\", \"hovermode\", \"xaxis_title\", \"yaxis_title\", \"colorbar\", \"colorscale\", \"coloraxis\", \"title_x\", \"bargap\", \"bargroupgap\", \"xaxis_tickformat\", \"yaxis_tickformat\", \"title_y\", \"legend_title_text\", \"xaxis_showgrid\", \"xaxis_gridwidth\", \"xaxis_gridcolor\", \"yaxis_showgrid\", \"yaxis_gridwidth\", \"yaxis_gridcolor\", \"showlegend\", \"xaxis_tickmode\", \"yaxis_tickmode\", \"margin\", \"xaxis_visible\", \"yaxis_visible\", \"bargap\", \"bargroupgap\", \"coloraxis_showscale\", \"xaxis_tickangle\"}\n",
        "\n",
        "def imshow(tensor: t.Tensor, renderer=None, **kwargs):\n",
        "    kwargs_post = {k: v for k, v in kwargs.items() if k in update_layout_set}\n",
        "    kwargs_pre = {k: v for k, v in kwargs.items() if k not in update_layout_set}\n",
        "    facet_labels = kwargs_pre.pop(\"facet_labels\", None)\n",
        "    border = kwargs_pre.pop(\"border\", False)\n",
        "    return_fig = kwargs_pre.pop(\"return_fig\", False)\n",
        "    text = kwargs_pre.pop(\"text\", None)\n",
        "    xaxis_tickangle = kwargs_post.pop(\"xaxis_tickangle\", None)\n",
        "    static = kwargs_pre.pop(\"static\", False)\n",
        "    if \"color_continuous_scale\" not in kwargs_pre:\n",
        "        kwargs_pre[\"color_continuous_scale\"] = \"RdBu\"\n",
        "    if \"color_continuous_midpoint\" not in kwargs_pre:\n",
        "        kwargs_pre[\"color_continuous_midpoint\"] = 0.0\n",
        "    if \"margin\" in kwargs_post and isinstance(kwargs_post[\"margin\"], int):\n",
        "        kwargs_post[\"margin\"] = dict.fromkeys(list(\"tblr\"), kwargs_post[\"margin\"])\n",
        "    fig = px.imshow(to_numpy(tensor), **kwargs_pre).update_layout(**kwargs_post)\n",
        "    if facet_labels:\n",
        "        # Weird thing where facet col wrap means labels are in wrong order\n",
        "        if \"facet_col_wrap\" in kwargs_pre:\n",
        "            facet_labels = reorder_list_in_plotly_way(facet_labels, kwargs_pre[\"facet_col_wrap\"])\n",
        "        for i, label in enumerate(facet_labels):\n",
        "            fig.layout.annotations[i]['text'] = label\n",
        "    if border:\n",
        "        fig.update_xaxes(showline=True, linewidth=1, linecolor='black', mirror=True)\n",
        "        fig.update_yaxes(showline=True, linewidth=1, linecolor='black', mirror=True)\n",
        "    if text:\n",
        "        if tensor.ndim == 2:\n",
        "            # if 2D, then we assume text is a list of lists of strings\n",
        "            assert isinstance(text[0], list)\n",
        "            assert isinstance(text[0][0], str)\n",
        "            text = [text]\n",
        "        else:\n",
        "            # if 3D, then text is either repeated for each facet, or different\n",
        "            assert isinstance(text[0], list)\n",
        "            if isinstance(text[0][0], str):\n",
        "                text = [text for _ in range(len(fig.data))]\n",
        "        for i, _text in enumerate(text):\n",
        "            fig.data[i].update(\n",
        "                text=_text,\n",
        "                texttemplate=\"%{text}\",\n",
        "                textfont={\"size\": 12}\n",
        "            )\n",
        "    # Very hacky way of fixing the fact that updating layout with new tickangle only applies to first facet by default\n",
        "    if xaxis_tickangle is not None:\n",
        "        n_facets = 1 if tensor.ndim == 2 else tensor.shape[0]\n",
        "        for i in range(1, 1+n_facets):\n",
        "            xaxis_name = \"xaxis\" if i == 1 else f\"xaxis{i}\"\n",
        "            fig.layout[xaxis_name][\"tickangle\"] = xaxis_tickangle\n",
        "    return fig if return_fig else fig.show(renderer=renderer, config={\"staticPlot\": static})\n",
        "\n",
        "def reorder_list_in_plotly_way(L: list, col_wrap: int):\n",
        "    '''\n",
        "    Helper function, because Plotly orders figures in an annoying way when there's column wrap.\n",
        "    '''\n",
        "    L_new = []\n",
        "    while len(L) > 0:\n",
        "        L_new.extend(L[-col_wrap:])\n",
        "        L = L[:-col_wrap]\n",
        "    print(f\"Reordered labels: {L_new}\")\n",
        "    return L_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNLip8nbp6vZ"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    DI_ROOT = Path(\"/content/devinterp-automata-main/\")\n",
        "    config_file_path = DI_ROOT / f\"scripts/configs/slt_config.yaml\"\n",
        "    slt_config = OmegaConf.load(config_file_path)\n",
        "    with open(DI_ROOT / f\"scripts/configs/task_config/{slt_config.dataset_type}.yaml\", 'r') as file:\n",
        "        task_config = yaml.safe_load(file)\n",
        "else:\n",
        "    config_file_path = \"scripts/configs/s;t_config.yaml\"\n",
        "    slt_config = OmegaConf.load(config_file_path)\n",
        "    with open(f\"scripts/configs/task_config/{slt_config.dataset_type}.yaml\", 'r') as file:\n",
        "        task_config = yaml.safe_load(file)\n",
        "\n",
        "OmegaConf.set_struct(slt_config, False) # Allow new configuration values to be added\n",
        "slt_config[\"task_config\"] = task_config\n",
        "# Convert OmegaConf object to MainConfig Pydantic model for dynamic type validation - NECESSARY DO NOT SKIP\n",
        "pydantic_config = PostRunSLTConfig(**slt_config)\n",
        "# Convert back to OmegaConf object for compatibility with existing code\n",
        "slt_config = OmegaConf.create(pydantic_config.model_dump())\n",
        "\n",
        "print(task_config[\"dataset_type\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEFYiG-EqAuR"
      },
      "outputs": [],
      "source": [
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "# Run path and name for easy referral later\n",
        "run_path = f\"{slt_config.entity_name}/{slt_config.wandb_project_name}\"\n",
        "run_name = slt_config.run_name\n",
        "\n",
        "# Get run information\n",
        "api = wandb.Api(timeout=3000)\n",
        "run_list = api.runs(\n",
        "    path=run_path,\n",
        "    filters={\n",
        "        \"display_name\": run_name,\n",
        "        \"state\": \"finished\",\n",
        "        },\n",
        "    order=\"created_at\", # Default descending order so backwards in time\n",
        ")\n",
        "assert run_list, f\"Specified run {run_name} does not exist\"\n",
        "run_api = run_list[slt_config.run_idx]\n",
        "try: history = run_api.history()\n",
        "except: history = run_api.history\n",
        "loss_history = history[\"Train Loss\"]\n",
        "accuracy_history = history[\"Train Acc\"]\n",
        "steps = history[\"_step\"]\n",
        "time = run_api.config[\"time\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYkD7_cIqEIh"
      },
      "outputs": [],
      "source": [
        "def get_config() -> MainConfig:\n",
        "    \"\"\"\"\n",
        "    Manually get config from run as artifact.\n",
        "    WandB also logs automatically for each run, but it doesn't log enums correctly.\n",
        "    \"\"\"\n",
        "    artifact = api.artifact(f\"{run_path}/config:{run_name}_{time}\")\n",
        "    data_dir = artifact.download()\n",
        "    config_path = Path(data_dir) / \"config.yaml\"\n",
        "    return OmegaConf.load(config_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgFUGT2lqHoA"
      },
      "outputs": [],
      "source": [
        "config = get_config()\n",
        "\n",
        "# Set total number of unique samples seen (n). If this is not done it will break LLC estimator.\n",
        "slt_config.rlct_config.sgld_kwargs.num_samples = slt_config.rlct_config.num_samples = config.rlct_config.sgld_kwargs.num_samples\n",
        "slt_config.nano_gpt_config = config.nano_gpt_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utSRu7dAqPbr"
      },
      "outputs": [],
      "source": [
        "def restore_state_single_cp(cp_idx: int) -> dict:\n",
        "    \"\"\"Restore model state from a single checkpoint.\n",
        "    Used in _load_logits_states() and _calculate_rlct().\n",
        "\n",
        "    Args:\n",
        "        idx_cp: index of checkpoint.\n",
        "\n",
        "    Returns:\n",
        "        model state dictionary.\n",
        "    \"\"\"\n",
        "    idx = cp_idx * config.rlct_config.ed_config.eval_frequency * slt_config.skip_cps\n",
        "    print(f\"Getting checkpoint {idx}\")\n",
        "    print(config.model_save_method)\n",
        "    match config.model_save_method:\n",
        "        case \"wandb\":\n",
        "            artifact = api.artifact(f\"{run_path}/states:idx{idx}_{run_name}_{time}\")\n",
        "            data_dir = artifact.download()\n",
        "            state_path = Path(data_dir) / f\"states_{idx}.torch\"\n",
        "            states = torch.load(state_path)\n",
        "        case \"aws\":\n",
        "            with s3.open(f'{config.aws_bucket}/{run_name}_{time}/states_{idx}.pth', mode='rb') as file:\n",
        "                states = torch.load(file, map_location=device)\n",
        "    return states[\"model\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYVaCV7BqiBy"
      },
      "outputs": [],
      "source": [
        "current_directory = Path().absolute()\n",
        "logits_file_path = current_directory.parent / f\"di_automata/logits_{run_name}_{time}\"\n",
        "print(logits_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMSwFPbSqnZE"
      },
      "outputs": [],
      "source": [
        "ed_loader = create_dataloader_hf(config, deterministic=True) # Make sure deterministic to see same data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cv2RNMe656c0"
      },
      "outputs": [],
      "source": [
        "def display_layer_heads(att, batch_idx=0):\n",
        "  display(cv.attention.attention_patterns(\n",
        "      tokens=list_of_strings(inputs[batch_idx,...]),\n",
        "      attention=att[batch_idx,...],\n",
        "      attention_head_names=[f\"L0H{i}\" for i in range(4)],\n",
        "  ))\n",
        "  # 0 is toggle action\n",
        "  # 1 is drive action\n",
        "  print(inputs[batch_idx,...])\n",
        "  print(labels[batch_idx,...])\n",
        "\n",
        "def list_of_strings(tensor):\n",
        "  return tensor.numpy().astype(str).tolist()\n",
        "\n",
        "\n",
        "def display_layer_heads_batch(att: torch.Tensor, cache: ActivationCache, toks: list[str]):\n",
        "  \"\"\"TODO: refactor\"\"\"\n",
        "  cv.attention.from_cache(\n",
        "    cache = cache,\n",
        "    tokens = toks,\n",
        "    batch_idx = list(range(10)),\n",
        "    attention_type = \"info-weighted\",\n",
        "    radioitems = True,\n",
        "    return_mode = \"view\",\n",
        "    batch_labels = lambda batch_idx, str_tok_list: format_sequence(str_tok_list, dataset.str_tok_labels[batch_idx]),\n",
        "    mode = \"small\",\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZnPaQSHYl0X"
      },
      "outputs": [],
      "source": [
        "print(config.rlct_config.ed_config.eval_frequency)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwIyM5v79Vh8"
      },
      "outputs": [],
      "source": [
        "# Form 1\n",
        "cp_idx_0 = 350\n",
        "state_0 = restore_state_single_cp(cp_idx_0)\n",
        "model_0, _ = construct_model(config)\n",
        "model_0.load_state_dict(state_0)\n",
        "\n",
        "# Form 2\n",
        "cp_idx_1 = 1000\n",
        "state_1 = restore_state_single_cp(cp_idx_1)\n",
        "model_1, _ = construct_model(config)\n",
        "model_1.load_state_dict(state_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sImbNx19xbt"
      },
      "outputs": [],
      "source": [
        "# Pass data through\n",
        "for data in take_n(ed_loader, 1):\n",
        "    inputs = data[\"input_ids\"]\n",
        "    labels = data[\"label_ids\"]\n",
        "    break\n",
        "\n",
        "logits_0, cache_0 = model_0.run_with_cache(inputs)\n",
        "logits_1, cache_1 = model_1.run_with_cache(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bagm4_EmBila"
      },
      "source": [
        "## First layer attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bffQ9LvZU_cP"
      },
      "outputs": [],
      "source": [
        "IDX = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmaqKeCt_qDn"
      },
      "outputs": [],
      "source": [
        "att_0_0 = cache_0[\"pattern\", 0, \"attn\"]\n",
        "display_layer_heads(att_0_0, batch_idx=IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GN1vmzk9AP5i"
      },
      "outputs": [],
      "source": [
        "att_1_0 = cache_1[\"pattern\", 0, \"attn\"]\n",
        "# for head in range(config.tflens_config.n_heads):\n",
        "#   imshow(att_1[0,head,...])\n",
        "display_layer_heads(att_1_0, batch_idx=IDX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvetCS-0BQ0P"
      },
      "source": [
        "## Second layer attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMYx1F3_-jI5"
      },
      "outputs": [],
      "source": [
        "att_0_1 = cache_0[\"pattern\", 1, \"attn\"]\n",
        "display_layer_heads(att_0_1, batch_idx=IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o83dGV5__ynD"
      },
      "outputs": [],
      "source": [
        "att_1_1 = cache_1[\"pattern\", 1, \"attn\"]\n",
        "display_layer_heads(att_1_1, batch_idx=IDX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3DKQq6cBXEZ"
      },
      "source": [
        "# Third layer attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKZ5sHS1AhFF"
      },
      "outputs": [],
      "source": [
        "att_0_2 = cache_0[\"pattern\", 2, \"attn\"]\n",
        "display_layer_heads(att_0_2, batch_idx=IDX)\n",
        "display_layer_heads(att_0_2, batch_idx=IDX+10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_i6jEhPAdVY"
      },
      "outputs": [],
      "source": [
        "att_1_2 = cache_1[\"pattern\", 2, \"attn\"]\n",
        "display_layer_heads(att_1_2, batch_idx=IDX)\n",
        "display_layer_heads(att_0_2, batch_idx=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEdJAvg6X5M4"
      },
      "outputs": [],
      "source": [
        "inputs_dict = {i: inputs[0][i].item() for i in range(inputs[0].shape[0])}\n",
        "labels_dict = {i: labels[0][i].item() for i in range(labels[0].shape[0])}\n",
        "\n",
        "for head in range(config.tflens_config.n_heads):\n",
        "  imshow_attention(att_1_2[0,head,...])\n",
        "  print(inputs_dict)\n",
        "  print(labels_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n385z-5vZmMh"
      },
      "outputs": [],
      "source": [
        "for head in range(config.tflens_config.n_heads):\n",
        "  imshow_attention(att_1_1[0,head,...])\n",
        "  print(inputs_dict)\n",
        "  print(labels_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln0H1jjC5td_"
      },
      "source": [
        "# OV circuit analysipost form 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTopEpN_5wbd"
      },
      "outputs": [],
      "source": [
        "print(cache_1[\"scale\"].shape)\n",
        "# Layernorm scale, [batch, pos, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBDMmooKRXAq"
      },
      "outputs": [],
      "source": [
        "# [nlayers nheads dmodel dhead] x [nlayers nheads dmodel dhead].T\n",
        "W_OV = model_0.W_V @ model_0.W_O # [nlayers nheads dmodel dmodel]\n",
        "W_E = model_0.W_E # [vocab_in dhead]\n",
        "W_U = model_0.W_U # [vocab_out dhead]\n",
        "print(W_E.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5yghQPRSkaF"
      },
      "outputs": [],
      "source": [
        "scale_final = cache_1[\"scale\"][:, :, 0].mean()\n",
        "scale_0 = cache_1[\"scale\", 0, \"ln1\"].mean()\n",
        "scale_1 = cache_1[\"scale\", 1, \"ln1\"].mean()\n",
        "scale_2 = cache_1[\"scale\", 2, \"ln1\"].mean()\n",
        "\n",
        "print(cache_1[\"scale\", 2, \"ln1\"].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsqqnbnMByqP"
      },
      "outputs": [],
      "source": [
        "print(W_OV[2].shape)\n",
        "print(W_OV[1].shape)\n",
        "print(W_OV[0].shape)\n",
        "print(W_OV.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-54mrBvTB4G"
      },
      "outputs": [],
      "source": [
        "# ! Get direct path\n",
        "W_E_OV_direct = (W_E / scale_final) @ W_U\n",
        "print(f\"Direct {W_E_OV_direct.shape}\") # [vocab_out vocab_out]\n",
        "\n",
        "# ! Get full OV matrix for path through just layer 0\n",
        "W_E_OV_0 = (W_E / scale_0) @ W_OV[0]\n",
        "W_OV_0_full = (W_E_OV_0 / scale_final) @ W_U # [n_head vocab_in vocab_out]\n",
        "print(f\"Layer 0 {W_OV_0_full.shape}\")\n",
        "\n",
        "# ! Get full OV matrix for path through just layer 1\n",
        "W_E_OV_1 = (W_E / scale_1) @ W_OV[1]\n",
        "W_OV_1_full = (W_E_OV_1 / scale_final) @ W_U # [n_head vocab_in vocab_out]\n",
        "print(f\"Layer 1 {W_OV_1_full.shape}\")\n",
        "\n",
        "# ! Get full OV matrix for path through just layer 2\n",
        "W_E_OV_2 = (W_E / scale_2) @ W_OV[2]\n",
        "W_OV_2_full = (W_E_OV_2 / scale_final) @ W_U # [n_head vocab_in vocab_out]\n",
        "print(f\"Layer 2 {W_OV_2_full.shape}\")\n",
        "\n",
        "# ! Get full OV matrix for path through heads in layer 0 and 1\n",
        "W_E_OV_01 = einops.einsum(\n",
        "    (W_E_OV_0 / scale_1), W_OV[1],\n",
        "    \"head0 vocab_in d_model_in, head1 d_model_in d_model_out -> head0 head1 vocab_in d_model_out\",\n",
        ")\n",
        "W_OV_01_full = (W_E_OV_01 / scale_final) @ W_U # [head0 head1 vocab_in vocab_out]\n",
        "print(f\"Layers 0, 1 {W_OV_01_full.shape}\")\n",
        "\n",
        "# ! Get full OV matrix for path through heads in layer 0 and 1\n",
        "W_E_OV_02 = einops.einsum(\n",
        "    (W_E_OV_0 / scale_1), W_OV[2],\n",
        "    \"head0 vocab_in d_model_in, head1 d_model_in d_model_out -> head0 head1 vocab_in d_model_out\",\n",
        ")\n",
        "W_OV_02_full = (W_E_OV_02 / scale_final) @ W_U # [head0 head1 vocab_in vocab_out]\n",
        "\n",
        "# Get full OV matrix for paths through heads in layer 1 and 2\n",
        "W_E_OV_12 = einops.einsum(\n",
        "    (W_E_OV_1 / scale_1), W_OV[2],\n",
        "    \"head0 vocab_in d_model_in, head1 d_model_in d_model_out -> head0 head1 vocab_in d_model_out\",\n",
        ")\n",
        "W_OV_12_full = (W_E_OV_12 / scale_final) @ W_U # [head0 head1 vocab_in vocab_out]\n",
        "\n",
        "# ! Get full OV matrix for path through heads in layer 0, 1, and 2\n",
        "W_E_OV_012 = einops.einsum(\n",
        "    (W_E_OV_01 / scale_2), W_OV[2],\n",
        "    \"head0 head1 vocab_in d_model_in, head2 d_model_in d_model_out -> head0 head1 head2 vocab_in d_model_out\",\n",
        ")\n",
        "W_OV_012_full = (W_E_OV_012 / scale_final) @ W_U # [head0 head1 head2 vocab_in vocab_out]\n",
        "print(f\"All layers {W_OV_012_full.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-adcLnLVLGk"
      },
      "outputs": [],
      "source": [
        "print(W_E_OV_direct[None, None].shape)\n",
        "print(W_OV_0_full[:, None].shape)\n",
        "print(W_OV_1_full[None].shape)\n",
        "print(W_OV_2_full[None].shape)\n",
        "print(W_OV_01_full.shape)\n",
        "\n",
        "cat_1 = torch.cat([W_E_OV_direct[None, None], W_OV_0_full[:, None]]) # [head0 1 vocab_in vocab_out]\n",
        "cat_2 = torch.cat([W_OV_1_full[None], W_OV_01_full])  # [head0 head1 vocab_in vocab_out]\n",
        "print(cat_1.shape, cat_2.shape)\n",
        "\n",
        "cat_3 = torch.cat([W_OV_02_full, W_OV_12_full])  # [head1 head2 vocab_in vocab_out]\n",
        "print(cat_3.shape)\n",
        "# cat_4 = torch.cat([W_OV_full[None], W_OV_2_full[None]]) # [head1 head2 vocab_in_ vocab_out]\n",
        "# print(cat_3.shape, cat_4.shape)\n",
        "\n",
        "W_OV_full_all = torch.cat([\n",
        "    cat_1,\n",
        "    cat_2,\n",
        "], dim=1) # [head0 head1 vocab_in vocab_out]\n",
        "# assert W_OV_full_all.shape == (5, 5, 8, 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h96abzNLYSup"
      },
      "outputs": [],
      "source": [
        "tokens = [str(i) for i in range(8)]\n",
        "components_0 = [\"W<sub>E</sub>\"] + [f\"0.{i}\" for i in range(4)]\n",
        "components_1 = [\"W<sub>U</sub>\"] + [f\"1.{i}\" for i in range(4)]\n",
        "components_2 = [\"W<sub>U</sub>\"] + [f\"2.{i}\" for i in range(4)]\n",
        "\n",
        "# Using dict.fromkeys() prevents repeats\n",
        "facet_labels = [\" ➔ \".join(list(dict.fromkeys([\"W<sub>E</sub>\", c0, c1, \"W<sub>U</sub>\"]))) for c1 in components_1 for c0 in components_0]\n",
        "imshow(\n",
        "    W_OV_full_all.transpose(0, 1).flatten(0, 1), # .softmax(dim=-1),\n",
        "    facet_col = 0,\n",
        "    facet_col_wrap = 5,\n",
        "    facet_labels = facet_labels,\n",
        "    title = f\"Full virtual OV circuits\",\n",
        "    x = tokens,\n",
        "    y = tokens,\n",
        "    labels = {\"x\": \"Source\", \"y\": \"Dest\"},\n",
        "    height = 1200,\n",
        "    width = 1200,\n",
        "    # text = text,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Po985XUk9AHx"
      },
      "outputs": [],
      "source": [
        "components_2 = [\"W<sub>U</sub>\"] + [f\"2.{i}\" for i in range(4)]\n",
        "cat_3 = torch.cat([W_E_OV_direct[None, None], W_OV_0_full[:, None]])  # [head1 head2 vocab_in vocab_out]\n",
        "print(cat_3.shape)\n",
        "cat_4 = torch.cat([W_OV_2_full[None], W_OV_02_full]) # [head1 head2 vocab_in_ vocab_out]\n",
        "print(cat_3.shape, cat_4.shape)\n",
        "\n",
        "W_OV_full_all = torch.cat([\n",
        "    cat_3,\n",
        "    cat_4,\n",
        "], dim=1) # [head0 head1 vocab_in vocab_out]\n",
        "# assert W_OV_full_all.shape == (5, 5, 8, 8)\n",
        "\n",
        "# Using dict.fromkeys() prevents repeats\n",
        "facet_labels = [\" ➔ \".join(list(dict.fromkeys([\"W<sub>E</sub>\", c0, c2, \"W<sub>U</sub>\"]))) for c2 in components_2 for c0 in components_0]\n",
        "imshow(\n",
        "    W_OV_full_all.transpose(0, 1).flatten(0, 1), # .softmax(dim=-1),\n",
        "    facet_col = 0,\n",
        "    facet_col_wrap = 5,\n",
        "    facet_labels = facet_labels,\n",
        "    title = f\"Full virtual OV circuits\",\n",
        "    x = tokens,\n",
        "    y = tokens,\n",
        "    labels = {\"x\": \"Source\", \"y\": \"Dest\"},\n",
        "    height = 1200,\n",
        "    width = 1200,\n",
        "    # text = text,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
