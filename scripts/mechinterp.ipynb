{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install git+https://github.com/callummcdougall/CircuitsVis.git#subdirectory=python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install git+https://github.com/callummcdougall/CircuitsVis.git#subdirectory=python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from pathlib import Path\n",
    "import os\n",
    "import yaml\n",
    "import s3fs\n",
    "import circuitsvis as cv\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import torch\n",
    "\n",
    "from di_automata.config_setup import *\n",
    "from di_automata.constructors import (\n",
    "    construct_model, \n",
    "    create_dataloader_hf,\n",
    ")\n",
    "from di_automata.tasks.data_utils import take_n\n",
    "\n",
    "# AWS\n",
    "s3 = s3fs.S3FileSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Notebook should be run under assumption that logits are already loaded in disk.\"\"\"\n",
    "config_file_path = \"configs/slt_config.yaml\"\n",
    "slt_config = OmegaConf.load(config_file_path)\n",
    "\n",
    "with open(f\"configs/task_config/{slt_config.dataset_type}.yaml\", 'r') as file:\n",
    "    task_config = yaml.safe_load(file)\n",
    "    \n",
    "OmegaConf.set_struct(slt_config, False) # Allow new configuration values to be added\n",
    "slt_config[\"task_config\"] = task_config\n",
    "# Convert OmegaConf object to MainConfig Pydantic model for dynamic type validation - NECESSARY DO NOT SKIP\n",
    "pydantic_config = PostRunSLTConfig(**slt_config)\n",
    "# Convert back to OmegaConf object for compatibility with existing code\n",
    "slt_config = OmegaConf.create(pydantic_config.model_dump())\n",
    "\n",
    "print(task_config[\"dataset_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Run path and name for easy referral later\n",
    "run_path = f\"{slt_config.entity_name}/{slt_config.wandb_project_name}\"\n",
    "run_name = slt_config.run_name\n",
    "\n",
    "# Get run information\n",
    "api = wandb.Api(timeout=3000)\n",
    "run_list = api.runs(\n",
    "    path=run_path, \n",
    "    filters={\n",
    "        \"display_name\": run_name,\n",
    "        \"state\": \"finished\",\n",
    "        },\n",
    "    order=\"created_at\", # Default descending order so backwards in time\n",
    ")\n",
    "assert run_list, f\"Specified run {run_name} does not exist\"\n",
    "run_api = run_list[slt_config.run_idx]\n",
    "try: history = run_api.history()\n",
    "except: history = run_api.history\n",
    "loss_history = history[\"Train Loss\"]\n",
    "accuracy_history = history[\"Train Acc\"]\n",
    "steps = history[\"_step\"]\n",
    "time = run_api.config[\"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in run_list:\n",
    "    print(run.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config() -> MainConfig:\n",
    "    \"\"\"\"\n",
    "    Manually get config from run as artifact. \n",
    "    WandB also logs automatically for each run, but it doesn't log enums correctly.\n",
    "    \"\"\"\n",
    "    artifact = api.artifact(f\"{run_path}/config:{run_name}_{time}\")\n",
    "    data_dir = artifact.download()\n",
    "    config_path = Path(data_dir) / \"config.yaml\"\n",
    "    return OmegaConf.load(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config: MainConfig = OmegaConf.create(run_api.config)\n",
    "config = get_config()\n",
    "\n",
    "# Set total number of unique samples seen (n). If this is not done it will break LLC estimator.\n",
    "slt_config.rlct_config.sgld_kwargs.num_samples = slt_config.rlct_config.num_samples = config.rlct_config.sgld_kwargs.num_samples\n",
    "slt_config.nano_gpt_config = config.nano_gpt_config\n",
    "\n",
    "model, param_inf_properties = construct_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_state_single_cp(cp_idx: int) -> dict:\n",
    "    \"\"\"Restore model state from a single checkpoint.\n",
    "    Used in _load_logits_states() and _calculate_rlct().\n",
    "    \n",
    "    Args:\n",
    "        idx_cp: index of checkpoint.\n",
    "        \n",
    "    Returns:\n",
    "        model state dictionary.\n",
    "    \"\"\"\n",
    "    idx = cp_idx * config.rlct_config.ed_config.eval_frequency\n",
    "    print(config.model_save_method)\n",
    "    match config.model_save_method:\n",
    "        case \"wandb\":\n",
    "            artifact = API.artifact(f\"{run_path}/states:idx{idx}_{run_name}_{time}\")\n",
    "            data_dir = artifact.download()\n",
    "            state_path = Path(data_dir) / f\"states_{idx}.torch\"\n",
    "            states = torch.load(state_path)\n",
    "        case \"aws\":\n",
    "            with s3.open(f'{config.aws_bucket}/{run_name}_{time}/states_{idx}.pth', mode='rb') as file:\n",
    "                states = torch.load(file)\n",
    "    return states[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = Path().absolute()\n",
    "logits_file_path = current_directory.parent / f\"di_automata/logits_{run_name}_{time}\"\n",
    "print(logits_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists(logits_file_path):\n",
    "#     print(f\"Loading existing logits from {logits_file_path}\")\n",
    "#     ed_logits = torch.load(logits_file_path)\n",
    "#     print(\"Done loading existing logits\")\n",
    "cusp_idx = 620\n",
    "cp_idx = cusp_idx // config.rlct_config.ed_config.eval_frequency\n",
    "print(cp_idx)\n",
    "print(time)\n",
    "\n",
    "state = restore_state_single_cp(cp_idx)\n",
    "model.load_state_dict(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_loader = create_dataloader_hf(config, deterministic=True) # Make sure deterministic to see same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in take_n(ed_loader, 1):\n",
    "    inputs = data[\"input_ids\"]\n",
    "    logits, cache = model.run_with_cache(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_1 = cache[\"pattern\", 0, \"attn\"]\n",
    "print(att_1)\n",
    "display(cv.attention.attention_patterns(\n",
    "    tokens=inputs,\n",
    "    attention=att_1,\n",
    "    attention_head_names=[f\"L0H{i}\" for i in range(12)],\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
